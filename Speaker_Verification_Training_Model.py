# Installation 
# !pip install pydub
# !pip install soundfile
# !pip install noisereduce

# Imports
from IPython.display import Audio
from pydub import AudioSegment
from scipy import stats
from scipy.io.wavfile import read
from sklearn.decomposition import PCA
from sklearn.mixture import GaussianMixture
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import IPython.display as ipd
import joblib
import librosa
import librosa.display
import matplotlib.pyplot as plt
import noisereduce as nr
import numpy as np
import os
import pandas as pd
import scipy as sp
import scipy.signal
import soundfile as sf

# -*- coding: utf-8 -*-
"""Speaker_Verification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1T0ppNaKKZDtACZXTrMQY74bxFG8MEceN
"""






"""---------------------------------MODEL TRAINING---------------------------------"""

path = '/content/drive/MyDrive/SpeakerVerification'  #Path of audios

path_list = []
for root,dirs,files in os.walk(path):        #Merging all the audios files
  for file in files:
    path_list.append(root+"/"+file)

id = set()
for i in path_list:
  id.add(i.split('/')[-3])       #Separating id's with path

did = {}
for i in id:
  temp = []
  for j in path_list:
    if i in j:
      temp.append(j)          #Mapping each id with it's path
  did[i] = temp

"""-----------------------------Feature Extracting-----------------------------------"""

def denoise_audio(input_file):

  audio, sr = librosa.load(input_file, sr=None)

  # Step 1: Estimate noise profile (use the first 1 second as noise)
  noise_sample = audio[:sr]  # First second of audio

  # Step 2: Apply noise reduction
  denoised_audio = nr.reduce_noise(y=audio, sr=sr, y_noise=noise_sample)

  return denoised_audio,sr

def extract_features(audio,sr,n_mfcc=64):
    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc)   #mfcc
    delta = librosa.feature.delta(mfcc)   #delta
    delta2 = librosa.feature.delta(mfcc, order=2)
    combined = np.concatenate((mfcc, delta, delta2))
    return combined.T

"""--------------------------------------Training Model----------------------------------"""

os.makedirs("/content/speaker_csv", exist_ok=True)
for speaker in did.keys():
  speaker_csv = pd.DataFrame()
  for file_path in did.get(speaker):
    feat = extract_features(file_path)
    speaker_csv = pd.concat([speaker_csv, pd.DataFrame(feat)])
  speaker_csv['Speaker'] = speaker
  speaker_csv.to_csv(f"/content/speaker_csv/{speaker}.csv", index=False)

"""--------------------------------------Train-Test-Split-----------------------------------------"""

train_data = {}
test_data = {}
for speaker in did.keys():
  train_data[speaker],test_data[speaker] = train_test_split(did[speaker],test_size=0.2) # split the datainto 80:20 ratio

csv_file = []
for file in os.walk('/content/speaker_csv'):
  csv_file.append(file)
csv_file = csv_file[0][2]

"""--------------------------------GMM MODEL----------------------------------"""

speaker_models = {}
for file in csv_file:
  df = pd.read_csv(f'/content/speaker_csv/{file}')
  X = df.drop(['Speaker'],axis=1)
  speaker = file.split(".")[-2]
  speaker_models[speaker] = GaussianMixture(n_components=20,max_iter=10)
  speaker_models[speaker].fit(X)

"""------------------------------Dumping the model into pkl---------------------------------------"""

os.makedirs("/content/model",exist_ok=True)
for speaker in speaker_models.keys():
  joblib.dump(speaker_models[speaker],f"/content/speaker_csv/{speaker}_model.pkl")

"""---------------------------Loading File------------------------------------"""

speaker1 = {}  #old model
for file in os.walk('/content/drive/MyDrive/speaker_csv/speaker_csv'):
  for f in file[2]:
    if '.pkl' in f:
      speaker1[f.split('.')[0].split('_')[0]] = joblib.load(f'/content/drive/MyDrive/speaker_csv/speaker_csv/{f}')

model = []
for speaker in speaker1.keys():
  model.append(speaker1[speaker])

with open("models1.pkl", "wb") as file:
    joblib.dump(model, file)